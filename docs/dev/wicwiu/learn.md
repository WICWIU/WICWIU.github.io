
이곳에서는 [**WICWIU**](https://github.com/WICWIU/WICWIU) 가 구성된 인공신경망을 통하여 어떻게 딥러닝을 하는지 설명합니다.

# 딥러닝 학습하기

## Step 1. 학습 데이터 &rarr; `Tensor`

1. 신경망을 학습시키기 위해 준비된 학습데이터를 먼저 `Tensor` 로 변환합니다. 

    !!! tip

        `tutorals/<DATA_NAME>/*Reader.hpp` 파일들을 참고하세요.

2. `FeedInput` 메소드를 사용하여 변환된 데이터를 신경망에 적용합니다.

    !!! warning

        입력의 크기가 신경망에서 기대하는 기대값 텐서 크기와 일치해야 하며, 일치하지 않을 경우 학습이 올바로 진행되지 않을 수 있습니다.

3. 위의 작업이 완료되면 신경망의 입력 공간에는 위의 `Tensor` (학습 데이터)가 등록되어 사용된다.

## Step 2. 순전파

1. 데이터가 적용된 신경망은 우선 이전의 값이 등록되어 있을 가능성이 존재하는 구간을 모두 $0$ 으로 초기화합니다. 

    !!! info 
    
        대표적으로는 연산에 참여하는 `Operator` 및 `LossFunction` 의 결과 `Tensor` 와 기울기벡터 `Tensor` 가 있습니다.

2. 위의 초기화 작업이 완료되면, 앞서 분석한 그래프의 `Operator` 의 순전파 연산을 순서대로 실행합니다. 

    !!! note 
        
        본 프레임워크의 신경망은 사용자가 추가한 `Operator` 의 연결상태를 **BFS** 로 분석하며, 이를 기준으로 신경망 연산을 진행합니다.

3. 모든 `Operator` 의 연산이 끝나면, 마지막으로 `LossFunction` 의 순전파를 실행하여 손실을 구합니다.

## Step 3. 역전파

손실이 구해진 신경망은, `LossFunction` 의 역전파 연산을 시작으로 각 `Operator` 의 반대 순서로 손실에 대한 기울기 벡터를 구합니다.

!!! note

    역전파 연산을 모두 마무리하면, 신경망에 적용된 Weight 파라미터들은 손실에 대한 기울기 벡터를 가지게 됩니다.

## Step 4. Weight 파라미터 갱신

각 Weight 파라미터는 신경망에 적용된 `Optimizer` 에서 지정된 알고리즘을 따라 최적화됩니다. 

!!! note 

    이때 사용하는 값은 앞서 역전파 연산으로 구해진 기울기 벡터이며, 이를 통해 신경망은 손실이 작아지는 방향으로 학습을 진행합니다.
